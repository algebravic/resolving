#+Title: Metric Dimension
#+Latex_header: \DeclareMathOperator{\wt}{wt}
* <2023-03-23 Thu> Introduction
Let $G$ denote a finite graph (directed or undirected). If $u,v \in
V(G)$ are two vertices of $G$ define $d(u,v)$ as being the length of
the shortest path from $u$ to $v$, and $+\infty$ if there is no such
path.  A *resolving set* for $G$ is a subset $S \subseteq V(G)$ such
that for each $u \ne v \in V(G)$ there is a $w \in S$ such that
$d(u,w) \ne d(v,w)$.  Clearly resolving sets exist, since $S = V(G)$
is one such.  The minimum cardinality of a resolving set is called the
*metric dimension* of $G$.

We are particularly interested in the metric dimension of the
hypercube $Q_n$ whose vertices are $\mathbb{F}_2^n$, and edges are
$(u,v)$ such that $u + v$ has weight 1.  Thus the distance metric $d$
is the *Hamming distance*.
** Using MAXSAT
One can approach this problem using ILP (integer linear programming)
or MAXSAT (maximum satisfiability).

For each pair $(u,v) \in V(G)$ with $u \ne v$ define the set
$P_{u,v} := \{w \in V(G) : d(v,w) \ne d(u,w)\}$.  We'll call this set the *pair
resolver*.

Clearly a set $S$ is resolving if and only if for each
$u \ne v \in  V(G)$
 we have $S \cap P_{u,v} \ne \emptyset$.  That is, $S$ contains
at least one element of each $P_{u,v}$.  In other terminology, $S$ is
a *hitting set* for the set system $\{P_{u,v} : u \ne v \in V(G) \}$.
** Questions
This brings up a number of practical questions:

1) Given a subset $S$ which is not a resolving set, efficiently
   produce a pair $(u,v)$ such that $d(w,u) = d(w,v)$ for all $w \in
   S$.  Can we do this without explicitly listing all resolving pairs?
2) Note that if $\sigma \in \text{Aut}(G)$ and $S$ is resolving then
   so is $\sigma(S)$.  This is true because $d(u,v) = d(\sigma u,
   \sigma v)$ for all $u,v \in V(G)$.

Possible approach: One only need to characterize the set of pairs
which have the same Hamming weight.

One might be able to do this inductively: Given a subset $S$, split it
into two subsets $S_0$ and $S_1$, distinguished by the first
coordinate, and denote by $\pi: \mathbb{F}_2^n \rightarrow
\mathbb{F}_2^{n-1}$ the projection onto the last $n-1$ coordinates.
A pair $(u,v)$ will be resolved by $S$ if and only if
a) $u_1 = v_1$ and $(\pi(u), \pi(v))$ is distinguished by $\pi(S)$.
b) $u_1 \ne v_1$ and $\pi(u)$ and $\pi(v)$ ...

An auxilliary question: Given a subset $S \subseteq \mathbb{F}_2^n$,
find an element $u \in \mathbb{F}_2^n$, such that $\max_{v \in S}
d(u,v)$ is minimized.  Call such a $u$ a *centroid* for $S$.

Maximum is hard to deal with.  Use the fact that average is a lower
bound to the maximum.  Suppose that $A_{i,j}$ is the $i$-th bit of the
$j$-th word in $S$.  Suppose that $x$ is the unknown centroid.

Form
\begin{displaymath}
\begin{split}
\sum_j \sum_i (x_i - A_{i,j})^2 & = \sum_i \sum_j (x_i + A_{i,j} -
2 x_i A_{i,j}) \\
 & = \sum_{i,j} A_{i,j} + |S| \text{wt}(x) - 2 \sum_i (\sum_j
A_{i,j}) x_i \\
& = \sum_{i,j} A_{i,j} - 2\sum_i (\sum_j (A_{i,j} - 1/2) - x_i).
\end{split}
\end{displaymath}

** Stabilizer by the hyperoctahedral group
The hyperoctahedral group is the group of automorphisms of $Q_n$.
More concretely, each automorphism is a pair $(\sigma, a)$ where
$\sigma \in S_n$, and $a \in \mathbb{F}_2^n$.  This acts as
$x \mapsto y$, where $y_i = x_{\sigma(i)} + a_i$.  What is the
stabilizer of an element?  We must have $x_i + a_i = x_{\sigma(i)}$.
This means that for each $\sigma$ there is a unique $a$ which makes
this true.  So each element has a stabilizer of order $n!$.  This
makes sense since the group is transitive.  What about subsets?
* Extended formulations
Here's the question: can we describe the hitting set problem more
economically?  More specifically can we specify the collection of
resolving sets more compactly with auxilliary variables?

So, to be more precise, Let $\mathcal{F}$ be a CNF formula in the set
of variables $V$.  We can think of it as specify a subset of $2^V$.  A
hitting set of this would be another subset $\mathcal{H}$ such that
for every $S \in \mathcal{F}$ there is a $T \in \mathcal{H}$ such that
$T \cap S \ne \emptyset$. 

* Some Results.

Let $Q^n$ denote the Hypecube, whose vertices are members
of $\mathbb{F}_2^n$ and whose edges connect two vertices whose weigh
differs by 1.   If $x \in \mathbb{F}_2^n$, let $\wt(x)$ denote the
*Hamming weight* of $x$, $\#\{1 \le i \le n: x_i = 1\}$, and $d(x,y)
:= \wt(x \oplus y)$.

Given $u,v \in \mathbb{F}_2^n$ let $R_{u,v} := \{ x \in
\mathbb{F}_2^n : d(x,u) \ne d(x,v) \}$.

Proposition: We have $R_{u,v} = u \oplus R_{0, u \oplus v}$.

Proposition: We have $R_{0,u} = \{ x \in \mathbb{F}_2^n:  2 \wt(u
\wedge x) \ne \wt(u)\}$. In particular, it includes all elements of
$\mathbb{F}_2^n$ if $u$ has odd weight.

Proof: Note that $\sum_{i=1}^n (-1)^{x_i} = \sum_{i=1}^n (1 - 2 * x_i)
= n - 2 \wt(x)$.  We have
$\wt(u \oplus x)  - \wt(x) = \sum_{i=1}^n ((u_i \oplus x_i) - x_i) =
$\sum_{i, u_i=1} (1- 2 * x_i) = \wt(u) - 2 \wt(u \wedge x)$.  So if $\wt(u)$ is
odd, this is always non-zero.

The equations to detect $(u,v)$ are similar (but not the same) as the
original ones:

* Bases
If $G$ is a permutation group, acting on a finite set $\Omega$, then a
*base* for $G$ is a subset $S \subseteq \Omega$ such that the subgroup
$\{ g \in G: g x = x, \forall x \in S\}$ is trivial. If $x_1, \dots,
x_m \in \Omega$ denote by $G_{x_1, \dots, x_m}$ the pointwise
stabilizer of all the $x_i$.  That is $G_{x_1, \dots, x_m} = \{g \in
G: g x_i = x_i, \forall 1 \le i \le m \}$.  The symmetry breaking
constaints can be of the following form:

Once we have chosen $x_1, \dots, x_m$, choose $x_{m+1}$ being members
of a set of representatives of distinct orbits of $\Omega$ under
$G_{x_1, \dots, x_m}$.  Call that set $S_{x_1, \dots, x_m}$.  The
clauses reprsenting this will be
$(x_1 \wedge \dots \wedge x_m \Rightarrow x)$ for all $x \in S_{x_1,
\dots, x_m}$.

Define: Let $G$ be a finite graph.  If $x,y \in V(G)$ the *resolving
set* of $(x,y)$, $R_{x,y} = \{ z \in V(G) : d(z,x) \ne d(z,y)\}$ is
the set of vertices which are at distinct distances from $x$ and $y$.

Define: An equivalence relation on the vertex set $V(G)$.  Say that
$x \sim y$ if, for all $z,w \in V(G)$ we have $d(x,z) = d(x,w)$ if and
only if $d(y,z) = d(y,w)$.  It is now clear that every resolving set
consists of a union of equivalence classes under this relation.
 
It is clear that if $\sigma$ is an automorphism of
$X$ then it is also a metric automorphism (i.e. $\sigma$ preserves
adjacency), but that might be other metric automorphisms.  A
particular example of a metric automorphism which is not a graph
automorphism occurs with the hypercube $Q^n$.  If $e$ is the all 1's
vector then $d(e \oplus x, y) = n - d(x,y)$. So the metric
automorphism group of $Q^n$ has order $2^{2n} n!$

* Some Proofs

Lemma: We have $R_{u,v} = u + R_{0,u+v}$.
Proof: By definition, $d(x,a) = \wt(x + a)$.  Thus, if $d(x,u) \ne
d(x,v)$, we have $\wt(x+u) \ne \wt(x+v)$.  But $\wt(x+u) = d(x+u,0)$
and $\wt(x+v) = d(x+u,u+v)$.

Corollary: If $S \subseteq V(Q^n)$ is a resolving set, then so is $u +
S$ for all $u \in V(Q^n)$.  Without loss of generality, we may assume
that any resolving set contains 0.

Lemma: If $e=(1, \dots, 1) \in V(Q^n)$, we have, for all $x \in
V(Q^n)$, $\wt(x+e) = n - \wt(x)$.

Corollary: For all $x \in R_{u,v}$ we have $x+e \in R_{u,v}$.

Definition: Denote by $\beta_n$ the metric dimension of $Q^n$.

Lemma: For all $n$ we have $\beta_n \le \beta_{n+1}$.
Proof:  Let $S$ be a minimum size resolving set for $Q^{n+1}$.  Let
$\pi : V(Q^{n+1}) \rightarrow V(Q^n)$ denote the map which removes the
last coordinate: $\pi((x_1, \dots, x_{n+1}) = (x_1, \dots, x_n)$, and
$\psi: V(Q^n) \rightarrow V(Q^{n+1})$ the map that adds a 0 coordinate
at the end.  That is $\psi((x_1, \dots, x_n)) = (x_1, \dots, x_n, 0)$.
Without loss of generality, by adding $e$ to any element of $S$ whose
last coordinate is 1, we may assume that the last coordinate of all
the elements of $S$ are 0.  It is clear that if $x,y \in V(Q^n)$ that
$d(x,y) = d(\psi(x), \psi(y))$.  However, by the assumption on $S$, we
have, for all $u \in S$, $u = \psi(\pi(u))$.  Thus $\pi(S)$ is a
resolving set for $Q^n$. QED.

Lemma: For all $m,n$ we have $\beta_{m+n} \le \beta_m + \beta_n$.  In
particular, since $\beta_1 = 1$, we have $\beta_{n+1} \le \beta_n +
1$.

Proof: Let $S$ be a resolving set for $Q^n$ and $T$ a resolving set
for $Q^m$.  Without loss of generality, we may assume that $0 \in S, 0
\in T$.  Define two maps $\phi: V(Q^m) \rightarrow V(Q^{m+n})$, $\phi:
V(Q^n) \rightarrow V(Q^{m+n})$ as follows $\phi((x_1, \dots, x_m)) =
(x_1, \dots, x_m, 0, \dots, 0)$, and $\psi((y_1, \dots, y_n)) = (1,
\dots, 1, y_1, \dots, y_n)$.  I claim that $U := \psi(S) \cup \phi(T)$
is a resolving set for $Q^{n+m}$.  Define maps $\rho: V(Q^{n+m})
\rightarrow V(Q^n)$ by $\rho((x_1, \dots, x_{m+n})) = (x_{m+1}, \dots,
x_{m+n}))$ and $\sigma: V(Q^{n+m}) \rightarrow V(Q^m)$ by
$\sigma((x_1, \dots, x_{m+n})) = (x_1, \dots, x_m)$.
We show that for all $x\ne y \in
V(Q^{m+n))$ there is an element of $U$ that resolves $(x,y)$. There
are three cases.

Note that for all $x,y$, $d(x,y) = d(\sigma(x), \sigma(y)) +
d(\rho(x), \rho(y))$.
Note that we have $\sigma \psi u = e$ and $\rho \psi u = u$,
$\sigma \phi v = v, \rho \phi v = 0$.

1) $\wt(\sigma(x)) = \wt(\sigma(y))$ and $\rho x \ne \rho y$.  Let $u \in S$ resolve $(\rho(x),
   \rho(y))$.  Then
   \begin{displaymath}
   \begin{aligned}
   d(\psi(u), x) - d(\psi(u), y) &= d(\sigma \psi u, \sigma x) + d(\rho \psi u, \rho  x)
                                                     -(d(\sigma \psi u, \sigma y) + d(\rho \psi u, \rho x)) \\
                                               &= d(e, \sigma x)  + d(u, \rho x) - (d(e, \sigma y)  + d(u, \rho y)) \\
                                               & = d(u, \rho x) - d(u, \rho y)
  \end{aligned}
   \end{displaymath}
   By hypothesis there is a $v \in T$ which resolves $(\rho x,
   \rho y)$.
   
2) $\wt(\rho(x)) = \wt(\rho(y))$ and $\sigma x \ne \sigma y$.  For $v \in T$
   \begin{displaymath}
   \begin{aligned}
   d(\phi(v), x) - d(\phi(v), y) &= d(\sigma \phi u, \sigma x) + d(\rho \phi u, \rho  x)
                                                     -(d(\sigma \phi u, \sigma y) + d(\rho \phi u, \rho x)) \\
                                               &= d(v, \sigma x)  + d(0, \rho x) - (d(v, \sigma y)  + d(0, \rho y)) \\
                                               & = d(v, \sigma x) - d(v, \sigma y)
  \end{aligned}
   \end{displaymath}
   By hypothesis there is a $v \in T$ which resolves $(\sigma x,
   \sigma y)$.
3) In the remaining cases either $\wt \sigma x \ne \wt \sigma y$ or
   $\wt \rho x \ne \wt \rho y$.  I assert that either 0, or $\psi 0$
   resolve $(x,y)$.  Namely
   \begin{displaymath}
   \begin{aligned}
   d(0, x) - d(0, y) &= d(\sigma 0, \sigma x) + d(\rho 0, \rho  x)
                                                     -(d(\sigma 0, \sigma y) + d(\rho 0, \rho x)) \\
                                               &= d(0, \sigma x)  + d(0, \rho x) - (d(0, \sigma y)  + d(0, \rho y)) \\
                                               & = (\wt \sigma x - \wt \sigma y) + (\wt \rho x - \wt \rho y)
  \end{aligned}
   \end{displaymath}
   and
   \begin{displaymath}
   \begin{aligned}
   d(\psi 0, x) - d(\psi 0, y) &= d(\sigma \psi 0, \sigma x) + d(\rho 0, \rho  x)
                                                     -(d(\sigma \psi 0, \sigma y) + d(\rho \psi 0, \rho x)) \\
                                               &= d(e, \sigma x)  + d(0, \rho x) - (d(e, \sigma y)  + d(0, \rho y)) \\
                                               &= -(\wt \sigma x - \wt \sigma y) + (\wt \rho x - \wt \rho y)
   \end{aligned}
   \end{displaymath}

* More efficient generation of hitting sets

Since the resolving set $R_{u,v} = u + R_{0, u+v} = v + R_{0, u+v}$,
we concentrate, first, on describing $R_{0,u}$.

Lemma: The set $R_{0,u} = \{ x : 2\wt(x \wedge u) \ne \wt(u)\}$.  In
particular, this means that if $\wt(u)$ is odd, then R_{0,u} =
\mathbb{F}_2^n$.

Proof: We first describe the complement of $R_{0,u}$.  By definition
$x \not \in R_{0,u}$ if $\wt(x) = \wt(x + u)$.  However $x = x
\wedge u + x \wedge \neg u$, where the two terms are disjoint.
Similarly $x+u = \neg x \wedge u + x \wedge \neg u$.
Thus $\wt(x) = \wt(x+u)$ if and only if $\wt(x \wedge u) = \wt(\neg x \wedge
u)$. Here $\wedge$ is elementwise.  The latter is true if and only if
$2 \wt(x \wedge u) = \wt(u)$.

We know find the size of the orbits of $R_{0,u}$ under the action of
the hyperoctahedral group.  To do that first, we find the order of the
stabilizer.  It suffice to consider only those $u$ of the form $(1,
\dots, 1, 0, \dots 0)$.  That is those in which $u_i = 1$ for $i=1,
\dots, t$ for $t$ even, and $u_i = 0$ for $i=t+1, \dots, n$.

Lemma: If $\wt(u), \wt(u')$ are even and $u \ne u'$ then $R_{0,u} \ne
R_{0,u'}$.

Proof: Since we may identify elements of $\mathbb{F}_2^n$ with subsets
of $[n] := \{1, \dots, n\}$.  Without loss of generality we may assume
that $\#U$ and $\#U'$ are both even, and that $\#U \ge \#U'$.
Let $X_1$ be a subset of $U \cap U'$ of cardinality $\lfloor \#(U \cap
U') / 2 \rfloor$, $X_2$ a subset of $U' \backslash U$ of cardinality
$\lceil \#(U' \backslash U) / 2\rceil$.
If we choose $X$ so that $w := \# (X \cap U') \ne \frac 1
2 \#U'$, then $x \in R_{0,u'}$.  Choose $X$ so that $\#(X \cap (U
\backslash U')) = \lfloor \# (U \backslash U') / 2 \rfloor$.
R_{0, u'}$.  If $\#(U \backslash U') \ge \frac 1 2 \#U$, then we may
choose $X$ to be contained in $\#(U \backslash U')$ and have
cardinality $\frac 1 2 \#U$
It suffices to prove that there exists a
$X \subset [n]$ such that $2 \#(X \cap U) = \#U$, and $2 \#(X \cap U')
\ne \#U'$.   It is clear that such an $X$ exists if and only if such
an $X$ exists with $X \subseteq U \cup U'$.
So let $w_1 = \#(X \cap (U \cap U'))$, $w_2 = \#(X \cap (\overline{U}
\cap U'))$, $w_3 = \#(X \cap (U \cap \overline{U'}))$.
Then $\#(X \cap U) = w_1 + w_3$, $\#(X \cap U') = w_1 + w_2$.
Similarly let $z_1 = \#(\overline{X} \cap (U \cap U'))$, $z_2 = \#(\overline{X} \cap (\overline{U}
\cap U'))$, $z_3 = \#(\overline{X} \cap (U \cap \overline{U'}))$.
Then $\#U = w_1 + w_3 + z_1 + z_3$, $\#U' = w_1 + w_2 + z_1 _+ z_2$.
$\#U = 2 w_1 + 2 w_3$, $\#U' = 2 w_1 + 2 w_2 + 2 y$ with $y \ne 0$
\begin{displaymath}
A =
\begin{pmatrix}
1 & 0 & 1 & 1 & 0 & 1 & 0\\
1 & 1 & 0 & 1 & 1 & 0 & 0\\
2 & 0 & 2 & 0 & 0 & 0 & 0\\
2 & 2 & 0 & 0 & 0 & 0 & 2
\end{pmatrix}
\end{displaymath}
Eliminating:
Elimnate $w_1$: (a) $\#U - \#U'$ = w_3 - w_2 + z_3 - z_2$
(b) $\#U = 2 z_1 + 2 z_3 - 2 w_3$, (c) $\#U' = 2 z_1 + 2 z_2 - 2 w_2 - y$.
Eliminate $z_1$: (b) - (c)
(d) $\#U - \#U' = 2 z_3 + 2 w_2 - 2 w_3 - 2 z_2 + 2 y$.
Add (a) + (1/2) (d): $\#U - \#U' = 2 z_3 - 2 z_2 +  y$

Without loss of generality we may assume that $\#U \ge \#U'$.
The kernel 
* <2023-04-25 Tue> Finding resolvers

Here's the problem:

We're given A partition $[r,s,s]$ of $n=r + 2s$ corresponding to
 putting all 0's in the $r$ part, all 1's in the first $s$ part and
 all $-1$s in the second $s$ part. We'd like to find all 0/1 tuples
 so that $x \cdot s != 0$ in efficient way.  First, the ones in the
 first part (or size $r$) can be arbitrary.  The only restriction both
 necessary and sufficient, is that the number of 1's in both of the
 $r$ parts are not equal.  Since we're only interested in those
 assignments which are inequivalent under permutations preserving the
 partition, we should put all the 1's first, before the 0's.  The
 number of assignments that yield 0 is then
\begin{displaymath}
2^r \sum_{j=0}^s \binom{s}{j}^2.
\end{displaymath}
Recall that if $f(x) = \sum_{j=0}^s \binom{s}{j}x^j = (1+x)^s$, then
$f(x) ^ 2 = \sum_{j=0}^{2s} (\sum_{i=0}^{\min{j,s}} \binom{s}{i}
\binom{s}{j-i}) x^j$.  The coefficient of $x^s$ in this is
$\sum_{i=0}^s \binom{s}{i}\binom{s}{s-i} = \sum_{i=0}^s
\binom{s}{i}^2$.  Thus this is $\binom{2s}{s}$.

* <2023-04-25 Tue> Certifying resolving

If we're given a putative resolving set as an $m \times n$ matrix, $A$
whose rows are the members of the set, either it does not resolve, on
which case a SAT solver can find a pair of nodes which can't be
distinguished, say, $u,v$.  This is equivalent to $A (u-v) = 0$.  If
it does resolve, we'd like a good certificate.  This is equivalent to
showing that the only solution to $A x = 0$ where all the coordinates
of $x$ are $0,\pm 1$ is the 0 vector.  This would be equivalent to the
there being no 0/1 solutions to $A (x-y) = 0$ with $x_i + y_i \le 1$
and $\sum_i (x_i + y_i) \ge 1$.  So, how many $0,\frac 12$ cuts would
we need to show this?  Somehow I think that I can reduce this to a
decoding problem for linear codes over GF(2).

First note that we can massage the matrix $A$ so that it's a 0/1
matrix.  If $e$ is the all 1 vector we then have $Ax + Ay  \le A e$.
Adding this to $Ax - Ay = 0$ we get $2Ax \le A e$. 

* <2023-04-27 Thu> An LP certificate?

Suppose that we want to verify that the metric dimension is $> m$.
This would be equivalent to the fact that for all $m \times n$ 0/1
matrices $A$ we have $Ax = 0$ there exists $x \in \{0,1,-1\}^n$, such that
$e^T x = 0$, where $e$ is the all 1's vector, and $x \ne 0$.

Another try: Consider only those vectors $y$ which have precisely one
coordinate +1 and one coordinate -1 and the rest 0.   Note that all
test vectors $x$ can be written as a sum of such vectors.  Thus if all
$y$ vectors satisfy $Ay = 0$ then so do all $x$ vectors.  So, taking
negation, if there exists an $x$ vector with $Ax \ne 0$ then there
exists a $y$ vector with $Ay \ne 0$.  However, even if there is a $y$
vector with $Ay \ne 0$, that doesn't mean that there isn't a sum of
such that yields 0.

This suggests an incremental method.  Start with a solution to all
weight 2 vectors.  From the solution we can find a description of all
disjoint sums which yield 0.  Add those clauses as conflict clauses.
In particular, one can just consider pairs 

Incrementally we can do the following: set up two sat solvers.
One of them will either find a counterexample, or, by showing UNSAT,
that all pairs are resolved.  We can have assumptions which are set to
the the current assignment for the $A$ matrix.  If it finds a
counterexample it will also generate other counterexamples by
permuting coordinates, with each permutation preserving the current A
matrix.   There may be too many permutations, so one would just want
to use a small generating set of the stabilizer.  An observation,
since there are lots of symmetries, one would like symmetry breaking
clauses.  First, since negating a test vector with nonzero value also
gives one with a nonzero value one can assume that the the nonzero
value is $\ge 1$.  We also can assume that, within a sector, that the
-1 come first, then 0's, then 1.  We can encode that in terms of the
assumption variables.  Note that if we take as necessary that all
columns are distinct, then all sectors have size 1, so this is
unnecessary.

This looks like a possible Skolem function: Given a boolean formula
$\phi(X,Y)$, where we want $\forall X \exists Y \phi(X,Y)$, is there a
boolean function $F(X)$ such that $\phi(X,F(X))$ is a tautology?

$E(X,Y,Y') := \phi(X,Y) \vee \neg \phi(X,Y') \vee (Y' \LeftRightArrow F(X))$
If $E$ is UNSAT, things are good, otherwise it produces a
counterexample.  How to repair?  They use MAXSAT.  Hard clauses
$E(X,Y,Y') := \phi(X,Y) \vee \neg \phi(X,Y')$.
soft $Y' \LeftRightArrow F(X)$

The other SAT solver will have the initial "bare bones" problem with
successive conflict clauses.

Another aside: If $n$ is large it's probably better to use Hermite
normal form of the putative $A$ matrix to find it's kernel.  We then
have a lattice which will contain all possible countexamples.  One
could aggresively reduce this.

This is equivalent (?) to the following: let $V = \{A \in
\RR^{m \times n} : A x = 0, \forall x \in \{0,-1,1\}^n, e^T x = 0\}$.
Then we want all 0/1 matrices $A$ to be contained in $V$.  Since $V$
is convex this is equivalent to $[0,1]^{m \times n} \subseteq V$.
More details:  It's clear that $V$ is a linear subspace.  So let $W$
be the linear subspaces of $\RR^n$ which is spanned by $\{x \in
\{0,-1,1\}^n, e^T x = 0, x \ne 0\}$.  Then $V = \{A \in \RR^{m \times
n} : A v = 0, \forall v \in W\}$.  Conversely, if $[0,1]^{m \times n}
\not \subseteq V$, that's the set in which we can find a resolving
matrix.

Something is wrong with above since $[0,1]^n$ is full dimensional but
$V$ clearly is not.

Aside: If $U, V$ are convex sets is $U \backslash V$ either empty or
convex?   No, clearly not, consider the complement of $[0,1]^n$.

* <2023-04-27 Thu> Using a solver with assumptions
A solver with assumptions has the following property:
You can invoke it giving it a list of literals which are assumed
true.  The use of this is to be able to "turn clauses on and off".
For example this is used in RC2.



